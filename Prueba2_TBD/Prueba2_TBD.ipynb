{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-47.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-19.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-112.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-12.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1    2    3     4     5     6      7     8     9   10  ...    56    57  \\\n",
       "0 -47.0 -6.0 -5.0  -7.0  13.0  -1.0   35.0 -10.0  10.0 -4.0  ... -25.0  47.0   \n",
       "1 -19.0 -8.0 -8.0  -8.0 -21.0  -6.0  -79.0  12.0   0.0  5.0  ... -83.0   7.0   \n",
       "2   2.0  3.0  0.0   2.0   0.0  22.0  106.0 -14.0 -16.0 -2.0  ... -38.0 -11.0   \n",
       "3   6.0  0.0  0.0  -2.0 -14.0  10.0  -51.0   5.0   7.0  0.0  ...  38.0 -35.0   \n",
       "4  15.0 -5.0 -5.0 -15.0  12.0 -22.0  -38.0  36.0   9.0  6.0  ... -26.0   5.0   \n",
       "5 -12.0 -5.0 -1.0   4.0 -16.0 -17.0  -69.0 -16.0 -12.0 -3.0  ...   1.0 -36.0   \n",
       "6  43.0  0.0 -2.0   6.0  11.0  26.0   51.0  27.0  -9.0 -2.0  ...  41.0  15.0   \n",
       "\n",
       "     58    59    60    61    62     63    64  out  \n",
       "0   6.0   6.0   5.0  13.0  21.0  111.0  15.0    0  \n",
       "1   7.0   1.0  -8.0   7.0  21.0  114.0  48.0    0  \n",
       "2   4.0   7.0  11.0  33.0  39.0  119.0  43.0    0  \n",
       "3  -8.0   2.0   6.0 -13.0 -24.0 -112.0 -69.0    0  \n",
       "4   6.0   6.0  11.0   5.0  30.0  -48.0  25.0    0  \n",
       "5 -10.0 -12.0 -16.0 -12.0 -47.0    6.0 -30.0    0  \n",
       "6   4.0  10.0  25.0   9.0  13.0   73.0  47.0    0  \n",
       "\n",
       "[7 rows x 65 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from pandas import Series, DataFrame\n",
    "from pylab import rcParams\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "## 1) Cargamos el dataset\n",
    "ppt = pd.read_csv(\"dataset-prueba2.csv\")\n",
    "ppt.columns = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40','41','42','43','44','45','46','47','48','49','50','51','52','53','54','55','56','57','58','59','60','61','62','63','64','out']\n",
    "ppt.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x114dae128>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.countplot(x='out',data=ppt, palette='hls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "5      0\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     0\n",
       "13     0\n",
       "14     0\n",
       "15     0\n",
       "16     0\n",
       "17     0\n",
       "18     0\n",
       "19     0\n",
       "20     0\n",
       "21     0\n",
       "22     0\n",
       "23     0\n",
       "24     0\n",
       "25     0\n",
       "26     0\n",
       "27     0\n",
       "28     0\n",
       "29     0\n",
       "30     0\n",
       "      ..\n",
       "36     0\n",
       "37     0\n",
       "38     0\n",
       "39     0\n",
       "40     0\n",
       "41     0\n",
       "42     0\n",
       "43     0\n",
       "44     0\n",
       "45     0\n",
       "46     0\n",
       "47     0\n",
       "48     0\n",
       "49     0\n",
       "50     0\n",
       "51     0\n",
       "52     0\n",
       "53     0\n",
       "54     0\n",
       "55     0\n",
       "56     0\n",
       "57     0\n",
       "58     0\n",
       "59     0\n",
       "60     0\n",
       "61     0\n",
       "62     0\n",
       "63     0\n",
       "64     0\n",
       "out    0\n",
       "Length: 65, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppt.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8755 entries, 0 to 8754\n",
      "Data columns (total 65 columns):\n",
      "1      8755 non-null float64\n",
      "2      8755 non-null float64\n",
      "3      8755 non-null float64\n",
      "4      8755 non-null float64\n",
      "5      8755 non-null float64\n",
      "6      8755 non-null float64\n",
      "7      8755 non-null float64\n",
      "8      8755 non-null float64\n",
      "9      8755 non-null float64\n",
      "10     8755 non-null float64\n",
      "11     8755 non-null float64\n",
      "12     8755 non-null float64\n",
      "13     8755 non-null float64\n",
      "14     8755 non-null float64\n",
      "15     8755 non-null float64\n",
      "16     8755 non-null float64\n",
      "17     8755 non-null float64\n",
      "18     8755 non-null float64\n",
      "19     8755 non-null float64\n",
      "20     8755 non-null float64\n",
      "21     8755 non-null float64\n",
      "22     8755 non-null float64\n",
      "23     8755 non-null float64\n",
      "24     8755 non-null float64\n",
      "25     8755 non-null float64\n",
      "26     8755 non-null float64\n",
      "27     8755 non-null float64\n",
      "28     8755 non-null float64\n",
      "29     8755 non-null float64\n",
      "30     8755 non-null float64\n",
      "31     8755 non-null float64\n",
      "32     8755 non-null float64\n",
      "33     8755 non-null float64\n",
      "34     8755 non-null float64\n",
      "35     8755 non-null float64\n",
      "36     8755 non-null float64\n",
      "37     8755 non-null float64\n",
      "38     8755 non-null float64\n",
      "39     8755 non-null float64\n",
      "40     8755 non-null float64\n",
      "41     8755 non-null float64\n",
      "42     8755 non-null float64\n",
      "43     8755 non-null float64\n",
      "44     8755 non-null float64\n",
      "45     8755 non-null float64\n",
      "46     8755 non-null float64\n",
      "47     8755 non-null float64\n",
      "48     8755 non-null float64\n",
      "49     8755 non-null float64\n",
      "50     8755 non-null float64\n",
      "51     8755 non-null float64\n",
      "52     8755 non-null float64\n",
      "53     8755 non-null float64\n",
      "54     8755 non-null float64\n",
      "55     8755 non-null float64\n",
      "56     8755 non-null float64\n",
      "57     8755 non-null float64\n",
      "58     8755 non-null float64\n",
      "59     8755 non-null float64\n",
      "60     8755 non-null float64\n",
      "61     8755 non-null float64\n",
      "62     8755 non-null float64\n",
      "63     8755 non-null float64\n",
      "64     8755 non-null float64\n",
      "out    8755 non-null int64\n",
      "dtypes: float64(64), int64(1)\n",
      "memory usage: 4.3 MB\n"
     ]
    }
   ],
   "source": [
    "ppt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Al parecer no hay datos nulos ni incoherencias en alguna fila o columna, por lo que los datos ya estan bastante\n",
    "#\"limpios\", ya que por falta de informacion no podemos ver si hay variables que no afecten directamente o no tengan importancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable objetivo\n",
    "y = ppt['out']\n",
    "# Variables predictivas (o explicativas)\n",
    "X = ppt.iloc[0:len(ppt),0:64]\n",
    "# Como la variable objetivo está en la ultima columna simplemente no la contamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state=25)\n",
    "\n",
    "from sklearn import tree\n",
    "#Entrenamiento\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[803  10  77]\n",
      " [  6 754  96]\n",
      " [ 60  97 724]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       890\n",
      "           1       0.88      0.88      0.88       856\n",
      "           2       0.81      0.82      0.81       881\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      2627\n",
      "   macro avg       0.87      0.87      0.87      2627\n",
      "weighted avg       0.87      0.87      0.87      2627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predicciones\n",
    "y_pred = clf.predict(X_test)\n",
    "#Evaluación del rendimiento del clasificador\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "#Print de la matriz de confusión\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92405063 0.8757259  0.80713489] [0.90224719 0.88084112 0.82179342]\n"
     ]
    }
   ],
   "source": [
    "# Acceso a los valores de presicion y recall\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "res = precision_recall_fscore_support(y_test, y_pred)\n",
    "presicion = res[0]\n",
    "recall = res[1]\n",
    "print(presicion, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Regresion logistica\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Aprendizaje\n",
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[404 230 256]\n",
      " [124 361 371]\n",
      " [212 305 364]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.45      0.50       890\n",
      "           1       0.40      0.42      0.41       856\n",
      "           2       0.37      0.41      0.39       881\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      2627\n",
      "   macro avg       0.44      0.43      0.43      2627\n",
      "weighted avg       0.44      0.43      0.43      2627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predicciones\n",
    "y_pred = LogReg.predict(X_test)\n",
    "#Evaluación del rendimiento del clasificador\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "#Print de la matriz de confusión\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[880   1   9]\n",
      " [  3 800  53]\n",
      " [ 25  31 825]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       890\n",
      "           1       0.96      0.93      0.95       856\n",
      "           2       0.93      0.94      0.93       881\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      2627\n",
      "   macro avg       0.95      0.95      0.95      2627\n",
      "weighted avg       0.95      0.95      0.95      2627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=15)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "#Predicciones\n",
    "y_pred = clf.predict(X_test)\n",
    "#Evaluación del rendimiento del clasificador\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "#Print de la matriz de confusión\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .7, random_state=25)\n",
    "\n",
    "from sklearn import tree\n",
    "#Entrenamiento\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "# probamos con un train size de 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1809   30  223]\n",
      " [   8 1779  241]\n",
      " [ 189  250 1600]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      2062\n",
      "           1       0.86      0.88      0.87      2028\n",
      "           2       0.78      0.78      0.78      2039\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      6129\n",
      "   macro avg       0.85      0.85      0.85      6129\n",
      "weighted avg       0.85      0.85      0.85      6129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predicciones\n",
    "y_pred = clf.predict(X_test)\n",
    "#Evaluación del rendimiento del clasificador\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "#Print de la matriz de confusión\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Regresion logistica\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Aprendizaje\n",
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[925 557 580]\n",
      " [263 844 921]\n",
      " [431 695 913]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.45      0.50      2062\n",
      "           1       0.40      0.42      0.41      2028\n",
      "           2       0.38      0.45      0.41      2039\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      6129\n",
      "   macro avg       0.45      0.44      0.44      6129\n",
      "weighted avg       0.45      0.44      0.44      6129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predicciones\n",
    "y_pred = LogReg.predict(X_test)\n",
    "#Evaluación del rendimiento del clasificador\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "#Print de la matriz de confusión\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2011    3   48]\n",
      " [   7 1879  142]\n",
      " [ 103   62 1874]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      2062\n",
      "           1       0.97      0.93      0.95      2028\n",
      "           2       0.91      0.92      0.91      2039\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      6129\n",
      "   macro avg       0.94      0.94      0.94      6129\n",
      "weighted avg       0.94      0.94      0.94      6129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=15)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "#Predicciones\n",
    "y_pred = clf.predict(X_test)\n",
    "#Evaluación del rendimiento del clasificador\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "#Print de la matriz de confusión\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podemos comparar las matriz confusion de cada metodo y podemos observar que al bajar el train size la presicion\n",
    "# aumenta, pero el recall disminuye, esto puede significar que a medida de que el train disminuye las veces que acierta\n",
    "# el modelo es cada vez mejor, pero comparado con el total de los valores reales del test, no es tan preciso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
